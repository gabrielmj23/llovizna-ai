{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y Preprocesar el Dataset\n",
    "dataset_dir = \"../datasets\"\n",
    "image_size = (480, 480)  # SpeciesNet EfficientNet V2 M espera 480x480\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(dataset_dir, \"train\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",  # o 'categorical' si usas one-hot encoding\n",
    "    image_size=image_size,\n",
    "    interpolation=\"nearest\",\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(dataset_dir, \"val\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    image_size=image_size,\n",
    "    interpolation=\"nearest\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # No es necesario barajar la validación\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(dataset_dir, \"test\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    image_size=image_size,\n",
    "    interpolation=\"nearest\",\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # No es necesario barajar la prueba\n",
    ")\n",
    "\n",
    "# Obtener los nombres de las clases (ordenados por el directorio)\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"Clases detectadas: {class_names}\")\n",
    "print(f\"Número de clases: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a185268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el aumento de datos (Data Augmentation)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomContrast(0.1),\n",
    "        # Puedes añadir más capas de aumento de datos aquí\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e22e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = (\n",
    "        tf.cast(image, tf.float32) / 255.0\n",
    "    )  # Escalar a [0, 1] si el modelo base lo requiere\n",
    "    # Si SpeciesNet usa EfficientNetV2, probablemente maneja su propia normalización\n",
    "    # Si no, deberías usar tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar aumento solo al conjunto de entrenamiento\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)\n",
    "test_ds = test_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizar el rendimiento de la carga de datos\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar SpeciesNet\n",
    "# base_model_path = os.path.join(os.path.dirname(__file__), \"speciesnet.keras\")\n",
    "# base_model = tf.keras.models.load_model(base_model_path)\n",
    "base_model = tf.keras.applications.EfficientNetV2M(\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False,  # Excluir la capa clasificadora superior\n",
    "    weights=\"imagenet\",  # Cargar los pesos pre-entrenados en ImageNet\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # No actualizar capas inferiores en las primeras épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6486505",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=image_size + (3,))\n",
    "x = inputs\n",
    "\n",
    "# Construir modelo de fine-tuning\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)  # Capa de dropout para regularización\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_initial = 10\n",
    "print(f\"\\nEntrenando las capas superiores por {epochs_initial} épocas...\")\n",
    "history_initial = model.fit(train_ds, epochs=epochs_initial, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Congelar capas de Batch Normalization (BN)\n",
    "# Es una práctica común dejar las capas de Batch Normalization congeladas durante el fine-tuning,\n",
    "# ya que sus estadísticas pueden volverse inestables con tamaños de batch pequeños.\n",
    "for layer in base_model.layers:\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Recompilar el modelo con un learning rate más bajo\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=1e-5\n",
    "    ),  # Learning rate más bajo para fine-tuning\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_fine_tune = 10  # Más épocas para el fine-tuning profundo\n",
    "total_epochs = epochs_initial + epochs_fine_tune\n",
    "\n",
    "print(\n",
    "    f\"\\nContinuando el entrenamiento (fine-tuning profundo) por {epochs_fine_tune} épocas...\"\n",
    ")\n",
    "history_fine_tune = model.fit(\n",
    "    train_ds,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history_initial.epoch[-1] + 1,\n",
    "    validation_data=val_ds,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Evaluar el Modelo ---\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(f\"\\nPrecisión en el conjunto de prueba: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Guardar el Modelo ---\n",
    "model.save(\"speciesnet_fine_tuned_model.h5\")  # O en formato SavedModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0aed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Visualizar el Historial de Entrenamiento ---\n",
    "def plot_history(history_initial, history_fine_tune):\n",
    "    acc = history_initial.history[\"accuracy\"] + history_fine_tune.history[\"accuracy\"]\n",
    "    val_acc = (\n",
    "        history_initial.history[\"val_accuracy\"]\n",
    "        + history_fine_tune.history[\"val_accuracy\"]\n",
    "    )\n",
    "    loss = history_initial.history[\"loss\"] + history_fine_tune.history[\"loss\"]\n",
    "    val_loss = (\n",
    "        history_initial.history[\"val_loss\"] + history_fine_tune.history[\"val_loss\"]\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label=\"Accuracy de Entrenamiento\")\n",
    "    plt.plot(val_acc, label=\"Accuracy de Validación\")\n",
    "    plt.plot(\n",
    "        [epochs_initial - 1, epochs_initial - 1],\n",
    "        plt.ylim(),\n",
    "        label=\"Inicio Fine-tuning\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Accuracy de Entrenamiento y Validación\")\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label=\"Pérdida de Entrenamiento\")\n",
    "    plt.plot(val_loss, label=\"Pérdida de Validación\")\n",
    "    plt.plot(\n",
    "        [epochs_initial - 1, epochs_initial - 1],\n",
    "        plt.ylim(),\n",
    "        label=\"Inicio Fine-tuning\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Pérdida de Entrenamiento y Validación\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history_initial, history_fine_tune)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
